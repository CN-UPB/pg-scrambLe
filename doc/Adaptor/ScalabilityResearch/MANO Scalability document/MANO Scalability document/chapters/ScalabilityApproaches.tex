\chapter{Scalability Approaches}
\label{ch:Scalability Approaches}

Some of the scaling approaches from various academic work are discussed in this chapter. In each section a brief introduction about each  scalability approach and the relavance of a specific approach to our context of research (MANO scalability) has been discussed.

\section{Service replication}

<<<<<<< HEAD
A technique to clone services running on other nodes to stabilize the service load among different nodes without causing any damage to the ongoing operations. Services that are replicated secure additional resources provided by the new nodes for handling larger service load. In other words, service replication enhances service scalability and reduces the risk of QoS degradation by handling larger service loads. In a case study, Falatah and Omar \cite{falatah_cloud_2014}, performed an analysis by varying the system load. Firstly, a variable for service load is set. The service load is a number of service invocations within a unit time. For the case study, the unit time was set to be 500ms. That is, if ten invocations occur within 500ms, then the service load is 10. To show an effectiveness of service replication, they simulate the service replication scheme for seventeen different volumes of service load. On each service load, conventional service system is compared with service replication strategy in terms of average response time.
=======
A technique to clone services running on other nodes to stabilize the service load among different nodes without causing any damage to the ongoing operations. Services that are replicated secure additional resources provided by the new nodes for handling larger service load. In other words, service replication enhances service scalability and reduces the risk of QoS degradation by handling larger service loads. In a case study, \cite{falatah_cloud_2014} Falatah and Omar performed an analysis by varying the system load. Firstly, a variable for service load is set. The service load is a number of service invocations within a unit time. For the case study, the unit time was set to be 500ms. That is, if ten invocations occur within 500ms, then the service load is 10. To show an effectiveness of service replication, they simulate the service replication scheme for seventeen different volumes of service load. On each service load, conventional service system is compared with service replication strategy in terms of average response time.
>>>>>>> [Updated] scalability research document : 2nd draft

Service replication is easier when the server is stateless, but the MANO will have a database, user session and various managed services. Simply replicating servers cannot be the solution as multiple MANOs using a single database will lead to a bottleneck. Hence, database clustering or database replication is also needed to maintain uniformity across the databases.  
Service replication increases availability and parallelism.


\section{Service Migration}

Service migration is a strategy of placing a service on a different node when a particular node cannot provide high QoS due to a hardware/software problem or due to the physical distance between consumers and providers. After service migration, the migrated service performs the same role that it was supposed to performed on the unstable node and the unstable node is removed from the list of service nodes.
The removal of this unstable node reduces overall QoS degradation.
Lee and Kim \cite{lee_software_2010} conducted a simulation where the service was migrated to a node that is located closer to consumer. There is also an assumption made that the response time is directly proportional to the distance. Hence, a service is migrated to the fastest node in terms of response time.

<<<<<<< HEAD
In terms of MANO, it manages VIMs. There is a close association between MANOs and VIMs to get an NS instatiated.
Mere migration of a MANO server closer to the user will not make the communication time between MANO and VIM faster. Therefore, in MANOs case, it seems like service replication is a better strategy.


\section{Proactive scaling}

Proactive scaling also known as scheduled scaling is mostly done in a cloud by scaling at predictable, fixed intervals or when big traffic stream is anticipated. A well-designed proactive scaling system enables providers to schedule capacity alterations based on a plan.
With scheduled scaling, one can set when to increase the capacity or number of servers and when to decrease them. To implement proactive scaling, one should first understand expected traffic flow, which means the providers should have some kind of statistics which indicates the desired (usual) traffic, deviation (usually high) from expected traffic \cite{falatah_cloud_2014} \cite{reese_cloud_nodate}. This type of scaling is suitable for servers that will have increased load during known days 

The MANO should be able to use traffic statistics and decide a scaling action. At the specified times, it should scale up with the values for normal, minimum or maximum traffic surges.


\section{Reactive scaling}

A reactive scaling strategy also known as auto-scaling adjusts its capacity by adding or removing, scaling up or down resources.
This type of scheme could be useful when the scheduled scaling plan goes wrong in proactive scaling. Cloud providers as well as cloud agencies require periodic acquisition of performance data for maintaining QoS. In addition, reactive scaling enables a provider to react quickly to unexpected demand. The crudest form of reactive scaling is utilization-based i.e. when  CPU, RAM  or some other resource reaches a certain level of  utilization, the provider adds  more of that resource to the environment \cite{falatah_cloud_2014} \cite{reese_cloud_nodate}. This type of scaling is suitable for servers that will have increased load only for a few days which cannot be predetermined.

In MANOs' terms, the plan is to develop a "Scalability Manager" plugin that could be installed in every MANO which helps scaling more children MANOs. It is the responsibilty of the scalability manager to scale MANOs and redirect the requests to the child MANO. Scaling decisions can be done when relevant metrics of a particular MANO reaches the threshold.


\section{Predictive scaling}
This type of scaling uses machine learning to predict the traffic stream of a server/application dynamically so that the capacity changes can be done accordingly, It collects data from all the server instances and various other data points and uses well trained machine learning models to predict the flow of traffic. This model would make use of one day's data and then the data is re-evaluated every 24 hours. This type of scaling strategy will be useful where servers are affected with cyclic periodic loads.

In terms of MANO, this type of scaling uses data from MANO instances and predicts the load on the server with the help of a machine learning model. This strategy is yet to be explored more to be incorporated in MANO.

=======
In terms of MANO, they typically manage VIMs. There is a close association between MANOs and VIMs to manage the lifecycle of an NS.
Mere migration of a MANO server closer to the operator will not make the communication time between MANO and VIM faster. Instead, migrating a service to a new instance of MANO closer to the VIMs will ease the communication between them hence improving the response time of service requests.
>>>>>>> [Updated] scalability research document : 2nd draft

\section{Service System Scaling - Dynamic node scaling}

To scale a distributed system with nodes spread over different locations, management components which help in monitoring the status of all these nodes are needed. Lee and Kim \cite{lee_software_2010} propose two key components to manage service scalability, Global Scalability Manager (GSM) and Regional Scalability Manager (RSM).

The key role of GSM is to manage service scalability. It balances service load in the system by obtaining the current status of nodes that are listed in the service system and designs a scalability strategy.

RSM component is installed on all the service nodes. It observes the status of its node and communicates it to the GSM. RSM also executes the scalability strategy based on instructions from the GSM. These two components assist the service system to add or remove new nodes dynamically at run-time.

\subsection{Service Scalability Assuring Process}


\begin{enumerate}
	

\item Define metrics for scalability measure. This metric are used to decide the raw data to be collected from services and to compute scalability in further steps.

\item Certain techniques from QoS monitored services are used to collect the set of raw data items \cite{Artaiam2008EnhancingSQ} \cite{hutchison_monitoring_2007}.

\item Analyze scalability metrics. If the metrics indicate an acceptable scalability level then continue step 2 and 3 where if the metrics indicate a need to repair the below averaged scalalability then execute the following steps. 

\item Develop a remedy plan for improving the below averaged scalability considering the current status of monitored service. Scalability assuring strategies like service replication and/or service migration could be adopted depending on the complexity and nature of the suffered service. 

\item The selected scalability strategy is executed and this is quite often an automated process. 

\item Inspect the result of the strategy and understand from the entire procedure as to how to improve the scalability. If the outcome of the process is valuable, then both the consequence and the remedy plan are logged for future uses thus making it a smart scalability framework.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/ServiceScalability}
	\caption{Service scalability Assuring Process from \cite{lee_software_2010}}
	\label{fig:servicescalability}
\end{figure}

\end{enumerate}

Similarly In MANO's context, the metrics defined in section \ref{Metrics} could be the basis for deciding the scalabiliy. GSM and RSM can be developed as part of MANO's ecosystem. The scalability strategy can be a hybrid of the approaches discussed in this chapter.
GSM can also be responsible for state management. When scaling down a MANO, the lifecycle management of certain network services which are a part of this MANO and other metadata are all transferred to a new active  MANO and the old MANO is deleted from the list of active MANOs.

<<<<<<< HEAD
\newpage
\section{Hierarchical Service Placement}
Service placement in a centralized network model lacks scalability. The service orchestrator in the centralized network model has a detailed view of all nodes/servers. A centralized placement algorithm maintaining all the information of all users and nodes is not a feasible approach. Maini et al. \cite{maini_hierarchical_2016} investigates a hierarchical solution where the overall orchestration domain is split into geographical sub-domains.

In this model, the authors refers to a node as an Execution Zone (EZ - Services will be deployed in datacenters/clouds). The high-level orchestrator has limited visibility of EZ and user demands within a sub-domain - it sees only the aggregate of user demands and the aggregate of EZ capacities within a particular sub-domain. The high-level orchestrator places service instances at the coarse granularity of sub-domain only. Subsequent sub-domain orchestrators undertake a further placement algorithm with the scope of that sub-domain to determine in which specific EZs what quantity of service instances should be placed to meet the specific demand pattern of user requests within that sub-domain \cite{maini_hierarchical_2016}.

\paragraph{}There are many ways of sub-dividing an overall orchestration domain into sub-domains. One option is to map sub-domains onto the same geographical area covered by resolution domains: the entity responsible for resolving user requests to EZs with available session slots. Another option is to consider multiple hierarchical levels of service orchestration and placement. The author models two levels of analysis.
=======
>>>>>>> [Updated] scalability research document : 2nd draft

 
 
