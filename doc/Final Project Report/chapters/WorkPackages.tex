\chapter{Work Packages}
\label{ch:WP}

\section{Translator}
\paragraph{}
In a hierarchical architecture involving different MANOs, there is a need of conversion of network descriptors to schemas of respective MANO. Service Descriptor Translator (SDT) serves the purpose of translating network descriptors, namely NSDs and VNFDs from schema of SONATA Pishahang to that of OSM and vice versa.
\paragraph{}
In a scenario, where a parent MANO, say Pishahang decides to deploy one of the network services in its lower hierarchy MANO, say OSM, the NSD and VNFD(s) need to be converted to the descriptor schema of OSM. In such an event, the Scramble plugin calls the translator service and sends the descriptors to the SDT, where the translation of the descriptors takes place and the translated descriptors are sent to Adaptor utility for deployment in appropriate MANO. Figure \ref{fig:service-descriptor-translator} gives a high level view of Translator.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"figures/Translator"}
	\caption{Translator}
	\label{fig:service-descriptor-translator}
\end{figure}

\subsection{Architecture \& Work flow}
The translator engine reads a json formatted descriptor and first converts it into a pandas \textit{DataFrame}. The \textit{DataFrame} object is constructed to have the following columns.

\begin{table}[H]
	\begin{center}
		\caption{Descriptor represented DataFrame.}
		\label{tab:table1}
		\begin{tabular}{l|l} 
			\textbf{Columns} & \textbf{Description} \\
			\hline
			\textbf{parent\_level} & It stores immediate parent key's depth-level \\ 
			\textbf{parent\_key} & It stores immediate parent key  \\
			\textbf{level} & It stores current key's depth-level \\
			\textbf{key} & It stores current key \\
			\textbf{value} & It stores current key's value \\
			\textbf{lineage} & \makecell[l]{It stores current key's entire lineage from the root depth-level.\\ It is useful to store the nested information} \\  
		\end{tabular}
	\end{center}
\end{table}

The \textit{setup} and \textit{transformation} classes of the translator engine carries out all the transformation, needed to translate between OSM and Pishahang descriptors, on the \textit{DataFrame} object. Once all the transformation are over, the resulting \textit{DataFrame} is then converted again into a json (refer Figure  \ref{fig:sequence-diagram-translator}).

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{"figures/translator_seq_diag"}
	\caption{Translator sequence diagram}
	\label{fig:sequence-diagram-translator}
\end{figure}


\subsection{Usage}
The Translator engine consists of the following modules (refer Figure  \ref{fig:class-diagram-translator}):
\begin{enumerate}
	\item descriptorReader
	\subitem class: read\_dict
	\item descriptorWriter
	\subitem class: write\_dict
	\item utilities
	\subitem class: setup
	\subitem class: transformation
	\subitem class: insert\_into\_db
	\item translator
	\subitem class: TranslatorService
	\item validator
	
\end{enumerate}

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\linewidth]{"figures/class_diagram_translator"}
	\caption{Translator class diagram}
	\label{fig:class-diagram-translator}
\end{figure}



\subsubsection{descriptorReader}
The class \textit{read\_dict} is responsible to read a json/dictionary input (NSD/VNFD) and iterate over the keys and return a generator of an object to the calling program. This generator can be transformed to any python data structure for ease of use and navigation. 

The input to this module is a json or dictionary object.

\begin{lstlisting}[language=Python,caption=reader to read a json into a DataFrame, label=lis:descriptorReader]
from descriptorReader import read_dict

pishahang = pishahang_descriptor ## the descriptor as a json or dict object

### reading a dict/ json content into a pandas dataframe
reader = read_dict()

pishahang_dataset = pd.DataFrame(
reader.dict_parser(pishahang,'root', 1, '0|preroot|0'), 
columns=['parent_level', 'parent_key', 'level', 'key', 'value', 'lineage'])


pishahang_dataset.sort_values(ascending=True, by=['level', 'parent_key'],inplace=True)
pishahang_dataset.fillna('NULL', inplace=True)
pishahang_dataset.reset_index(drop=True,inplace=True)

\end{lstlisting}
\subsubsection{descriptorWriter}

The class \textit{write\_dict} is responsible to read a python pandas Dataframe input and output a nested json/dictionary maintaining the nested structure in the dictionary.

\begin{lstlisting}[language=Python,caption=writer to write a translated DataFrame into a json, label=lis:descriptorWriter]
from descriptorWriter import write_dict

### writing from a pandas dataframe to a dict/json object
writer = write_dict()
pishahang_descriptor = writer.translate(pishahang_dataset.sort_values(by='lineage'))

\end{lstlisting}

\subsubsection{utilities}

The class \textit{setup} is responsible for transforming the keys and map the corresponding values between sonata and osm descriptors. The class includes 4 functions for translating between sonata and OSM descriptors. 
\begin{enumerate}
	\item translate\_to\_osm\_nsd()
	\item translate\_to\_osm\_vnfd()
	\item translate\_to\_sonata\_nsd()
	\item translate\_to\_sonata\_vnfd()
\end{enumerate}

The class \textit{transformation} acts as a helper class for the task of transforming the dataframe between sonata and OSM structures. 

\subsubsection{translator}

The class \textit{TranslatorService} is the interface where the actual translation request comes in. After a tranlsation request is received along with a descriptor, it calls the above modules translate and validate the descriptors (NSD/VNFD).

This following function translates OSM descriptor to Pishahang and vise-versa.
\begin{lstlisting}[language=Python,caption= Translating descriptor between Pishahang and OSM, label=lis:toSOnata]
import pymongo
from validate import validator
from utilities import setup


class TranslatorService():

def __init__(self,client = pymongo.MongoClient("mongodb://mongo:27017")):
self.setup_obj = setup(client)
self.validate_obj = validator()


def toSonata(self,received_file):

if 'vnfd:vnfd-catalog' in received_file:

doc = self.setup_obj.db_descriptors["translated_vnfd"]
translated = self.setup_obj.translate_to_sonata_vnfd(received_file)

check = self.validate_obj.sonata_vnfd_validate(translated)

if check == "True":
temp = doc.insert_one(translated)
translated_ref = temp.inserted_id

elif 'nsd:nsd-catalog' in received_file:

doc = self.setup_obj.db_descriptors["translated_nsd"]
translated = self.setup_obj.translate_to_sonata_nsd(received_file)

check = self.validate_obj.sonata_nsd_validate(translated)

if check == "True":
temp = doc.insert_one(translated)
translated_ref = temp.inserted_id

return {"descriptor":translated ,"VALIDATE STATUS" :check}

def toOsm(self,received_file):

if 'network_functions' in received_file:

doc = self.setup_obj.db_descriptors["translated_nsd"]
translated = self.setup_obj.translate_to_osm_nsd(received_file)

check= self.validate_obj.osm_validator(translated)

if check == "True":
temp = doc.insert_one(translated)
translated_ref = temp.inserted_id

elif 'virtual_deployment_units' in received_file:

doc = self.setup_obj.db_descriptors["translated_vnfd"]
translated = self.setup_obj.translate_to_osm_vnfd(received_file)

check= self.validate_obj.osm_validator(translated)

if check == "True":
temp = doc.insert_one(translated)
translated_ref = temp.inserted_id

return {"descriptor":translated ,"VALIDATE STATUS" :check}
\end{lstlisting}

\subsubsection{validator}

The validator validates the descriptors presented for translation. It differentiates between OSM, Pishahang and Sonata descriptors and also between NSD's and VNFD's. The sonata descriptor validation is mainly based on schema, implemented using python library jsonschema.draft4validator, this library helps by proving the complete path of the error which comes very handy while debugging. The Validation for OSM is slightly complex than that compared to sonata validator, OSM validator can be divided into two parts. the first part validates the descriptors using schema with the same setup as that of sonata and the second part uses python object class for validation, this is done to replicate the validation method used by OSM hence to make sure that any descriptor that is validated by translator will be accepted by OSM.

\subsection{Challenges}
The initial challenges faced while designing the translator was mapping the "\textit{required}" keys between OSM and Pishahang descriptors. Figuring out the common functionalities of the respective "\textit{required}" keys in OSM and Pishahang was the priority and a mapping was created. The other "\textit{optional}" keys which were exclusive for each MANOs were also identified and sidelined for future scope.

\subsection{Future scope of this work package}

Translator engine currently doesnot support the following:
\begin{enumerate}
	\item Forwarding Graph
	\item Juju charms in OSM
	\item Monitoring Parameters
\end{enumerate}

\subsubsection{Forwarding Graph}
Although translation of forwarding graphs between OSM and  Pishahang has been implemented, we could not verify the translation as the forwarding graph logic was not currently feasible during our implementation period in both OSM and Pishahang.

\subsubsection{Juju charms in OSM}
MANOs provide programmable and flexible management and orchestration of VNFs. OSM provides this flexibility through juju charms and Pishahang provides this through SSM/FSM (a container based solution). Because of these technological differences, direct translation between juju charms in OSM, and SSM (Service Specific Manager) and FSM (Function Specific Manager) in Pishahang is not possible. 

As an alternative, it is possible to add charms functionality to Pishahang so that a descriptor containing juju charms can be deployed in both Pishahang and OSM with direct translation. This can be achieved by adding or modifying below things in Pishahang.
\begin{enumerate}
	\item Modify packaging and unpackaging techniques in Pishahang to accept charm package along with descriptors
	\item Add additional keys in descriptors to mention charm name, actions and vnf index similar to OSM
	\item Update Pishahang installation code to install juju and charm programs and tools
	\item Create an interface to execute actions on VNFs
	\item Create new container or component to perform actions on specified VNFs
	\item Manage removal or deletion of charms after life cycle of Network Service 
\end{enumerate} 


\subsubsection{Monitoring Parameters}
Translation could be extended to include the monitoring parameters as well. However verifying monitoring parameters were not feasible in OSM during our implementation period, so we sidelined for future scope.

\newpage

\section{Splitter}
Figure \ref{fig:splitter} graphically represents the splitting architecture of SDS. SDS can split either OSM NSD or Pishahang NSD. Python base classes are used for different sections of a NSD which encapsulate all the attributes and its values into a single unit which makes it very easy to process. Once the objects are set they are passed to different splitting functions based on there type. We have two different processing units for OSM and SONATA. Following are some functions responsible for splitting the NSD.

\begin{itemize}
	\item \textbf{Validate: }Validation of the incoming request from MANO for splitting happens is done before actual splitting. Validation checks if the request has correct VNF ids. It also checks if the list of VNFs specified in the request is matching with the list of VNFs in the original NSD file.
	\item \textbf{Set connection point reference for virtual functions:}After validation, as per the incoming request multiple set of empty NSD objects are created. This step updates the empty NSD objects with connection points. These connection points are either of type “external” or “management”. Each sub NSD will have its own connection points just like its parent NSD.
	\item \textbf{Split Network Functions: }After creating connection points for each sub NSDs, VNF objects are set in the updated NSD objects as per the request from MANO. Each set of VNFs from the request is set in each of the NSD objects. 
	\item \textbf{Set Connection Points: }
	\item \textbf{Split Virtual Links: }When a NSD is splitted into different parts, its topology changes. Change in topology results in changing of Virtual Links. For example if A, B and C are three Nfs and we are splitting them in such a way so that A and B remain in one NSD and C in separate NSD. A virtual link between B and C now does not make sense. So this link should be broken down and B’s output should be connected to the external end point which was connected to C’s input earlier. This function splits these kind of Virtual Links.
	\item \textbf{Split Forwarding Graph: }As explained in the above section, once the topology changes, the respective Forwarding graph also changes. Split forwarding graph pulls out the set of connection points and newly created virtual links and sets them in the sub NSDs.
	\item \textbf{Set General Information: }
	\item \textbf{Create Sub-NSDs: }
\end{itemize} 

Once the Splitting is done, create file is responsible for creating YAML files depending on the number of sub NSDs created. These files are saved in the file system which can be downloaded or moved forward to the adopter for deployment purpose. Following figure \ref{fig:splitter} graphically represents the splitting architecture.



\subsection{Usage}

SDS is implemented as a micro-service which can be used independently from Translator or Wrapper by making a post call to the SDS. Following code snippet describes how to call SDS using POST call.

\begin{lstlisting}[caption=POST call to SDS, label=lis:postSDS]

splitter_url=http://$HOST:8003/Main_splitter/split

# Body: descriptor contains NSD, vnfid_set contains set of VNF ids
nsd = { 'descriptor' : descriptor, 'sets': vnfid_set}

LOG.info("Calling Scramble Splitter..." )
response  = requests.post(splitter_url,
data=json.dumps(nsd_to_split))

print(response)

\end{lstlisting}

Following are some of the important functions which helps SDS in splitting the NSD with respective code snippet.

\subsubsection{Basic Python classes for NSD Schema}
\subsubsection{Splitting} "splitsonata" calls the splitting function one by one to split the list of objects created out of NSD. Following code snippet shows the sequence of function calls.

\begin{lstlisting}[caption=Sequence of function calls, label=lis:functioncalls]

def split_sonata(self):
if self.validate() is not False:
self.create_new_function_sets()
self.set_connection_point_refs_for_virtual_functions()
self.split_network_function()
self.set_connection_points()
self.split_virtual_links()
self.split_forwarding_path()
self.set_general_information()
return self.create_files()
else:
print("Validation Failed!!")

\end{lstlisting}

\subsubsection{Validate} Validate method validates the request coming from the MANOs. For example, if MANO is requesting a NSD to be split into three parts but the original NSD contains just two VNFs then the SDS will throw validation error.

\begin{lstlisting}[caption=Splitting Request Validation, label=lis:validation]

def validate(self):
size = 0
list_network_function = []
for network_function_set in self.network_function_sets:
size = size + len(network_function_set)
for network_function in network_function_set:
list_network_function.append(network_function)

if size != len(self.utilityFunctions.list_nf):
return False
if len(list_network_function) != len(set(list_network_function)):
return False

\end{lstlisting}

\subsubsection{Split Network Functions}
This function updates the sub NSDs with set of network functions and there properties provided in the request.

\begin{lstlisting}[caption=Network Function Splitting, label=lis:NFSplitting]

def split_network_function(self):

for network_function_set in self.network_function_sets:

sub_nsd = SonataSchema.NSD("", "", "", "", "", "", [], [], [], [])

network_function_list = []

for network_function in network_function_set:

network_function_list.append(self.get_network_function_object(network_function))

sub_nsd.networkFunctions = network_function_list

self.NSDs.append(sub_nsd)

\end{lstlisting}

\subsubsection{Split Forwarding Graph}

\todo[inline]{Content to be added}
\subsection{Challenges}
The NSD schema of Pishahang and OSM contains a lot of elements. However the challenge we faced was choosing which elements to include for splitting. We tackled it by including mandatory elements and few optional elements from the schema which were present in the input NSD.
\subsection{Future scope of Service Descriptor Splitter}
SDS can currently split NSD of Pishahang and OSM. SDS is built in such a way that it can be implemented for MANO frameworks as well. To implement SDS for a new MANO framework one can refer the implementation of either Pishahang or OSM. First step would be to create basic python classes from the NSD schema of the MANO framework then writing the utility functions to pull the information from the NSD file and store it in the objects of the basic python classes. Lastly writing splitting functions to actually split the list of objects in two or more parts.

Also, the current implementation considers all mandatory elements and a few optional elements from a NSD schema for splitting which can be extended to include other fields (Provided they are present in the input NSD for splitting).

Current implementation of SDS can split a forwarding graph of a NSD (Pishahang) with just three VNFs. Splitting of a forwarding graph is implemented by keeping future implementation for more than three VNFs in mind (Refer Splitting of Forwarding graph section)

\include{adaptor-arch}

\section{Pishahang-Scramble Integration}

Service Life-cycle Management(SLM) component of Pishahang carries out the main task of orchestration. As a result it was all the more relevant to add one more aspect to it for integrating and handling Scramble components.

The main class of SLM, \textit{ServiceLifecycleManager}, contains a list of member functions for carrying out the entire orchestration. One of the many member functions, \textit{SLM\_mapping}, is responsible for handling the descriptors payload and creating a mapping of network funtions to the available VIMs. Keeping the original flow of SLM intact, we extended the main class to include a new member function (\textit{SLM\_mapping\_scramble}) to handle request addressed for mapping the network functions to the available MANOs.

When a request to instantiate the network service from the BSS (son-bss) is made, the gatekeeper (son-gkeeper) gets the request payload from BSS and creates a instantiation request to hand it over to SLM. For differentiating the instantiation request between a "\textit{normal}" call and a "\textit{scramble}" call, we added a "\textit{scramble}" button in BSS. 

\begin{lstlisting}[caption=BSS instantiateScramble function, label=lis:BSSscramble]
instantiateScramble:function(id, ingresses, egresses, ENV, selectedmanos, manodetails){				
var defer=$q.defer();

{...} ## unchanged

var data={"service_uuid":id, "ingresses": ingresses, "egresses": egresses, "scramble":true, "selectedmanos":selectedmanos, "manoips":manodetails};
$http.post(ENV.apiEndpoint+"/requests",data)
.then(function successCallback(result){defer.resolve(result)})
.catch(function errorCallback(error){defer.reject(error)});

return defer.promise;
},

\end{lstlisting}

This function sends the gatekeeper a payload which consists of a token "\textit{scramble}", which set to true, and a list of mano details.

The gatekeeper also ensures the payload contains this additional package when it creates a new instantiation request and informs the SLM. 

\begin{lstlisting}[caption=create instantiation request in gatekeeper(request.rb), label=lis:request.rb]

post '/requests/?' do
log_msg = MODULE + '::POST /requests'
original_body = request.body.read
logger.debug(log_msg) {"entered with original_body=#{original_body}"}
params = JSON.parse(original_body, quirks_mode: true)
logger.debug(log_msg) {"with params=#{params}"}

# we're not storing egresses or ingresses
egresses = params.delete 'egresses' if params['egresses']
ingresses = params.delete 'ingresses' if params['ingresses']
user_data = params.delete 'user_data' if params['user_data']

begin
{...} ## unchanged

if params['scramble'] == true
start_request['scramble'] = true 
start_request['selectedmanos'] = params['selectedmanos']
start_request['manoips'] = params['manoips']

end
{...} ## unchanged
end

\end{lstlisting}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{"figures/scramble_seq_diag"}
	\caption{Integration sequence diagram}
	\label{fig:sequence-diagram-scramble}
\end{figure}

\subsection{\textbf{SLM\_mapping\_scramble}}

This member function, together with four other helper functions, is responsible for treating requests routed for translation, splitting and sending the descriptor for instantiating in other MANOs. The 4 other helper functions used by it are as follows:
\begin{table}[H]
	\begin{center}
		\caption{Helper functions.}
		\label{tab:table2}
		\begin{tabular}{l|l} 
			\textbf{Functions} & \textbf{Description} \\
			\hline\\
			\textbf{get\_network\_functions} & \makecell[l]{It gets the network function names and ids from \\ the service descriptor.} \\\\
			\textbf{random\_combination} & \makecell[l]{It maps different network functions to different \\ MANOs in random combination.}  \\\\
			\textbf{send\_to\_osm} & \makecell[l]{This function sends one part of the splitted \\ service descriptor and its network functions to \\OSM Mano instance.} \\\\
			\textbf{send\_to\_pishahang} & \makecell[l]{This function sends one part of the splitted \\ service descriptor and its network functions to \\ PISHAHANG Mano instance.}\\\\
			\textbf{inform\_gk\_instantiation\_scramble} & \makecell[l]{This function is used to inform the gatekeeper to \\ create a dummy NSR in the only case when none \\ of the network functions, of the original NSD, are \\ instantiated by this SLM. This way the instantiation \\ request is not rolledback}
		\end{tabular}
	\end{center}
\end{table}

This function is created by extending the original \textbf{SLM\_mapping} function to include the logic to map each network functions to a MANO and then send and instantiate them in their mapped MANOs:

\begin{lstlisting}[language=Python,caption=Extended \textbf{SLM\_mapping\_scramble} function, label=lis:SLM_scramble]
def SLM_mapping_scramble(self, serv_id):
"""
This method is used if the SLM is responsible for the placement.
:param serv_id: The instance uuid of the service
"""
corr_id = str(uuid.uuid4())
self.services[serv_id]['act_corr_id'] = corr_id

LOG.info("Service " + serv_id + ": Calculating the placement ")
topology = self.services[serv_id]['infrastructure']['topology']

## getting all manos information from payload
mano_dict = self.services[serv_id]['payload']['selectedmanos']
mano_details = self.services[serv_id]['payload']['manoips']
mano_list = []

## creating a list of selected manos and its corresponding details
for key, val in mano_dict.items():
for manos in mano_details:
if manos['name']==key and val == True:
mano_list.append(manos)

## original flow with scramble portion added
if 'nsd' in self.services[serv_id]['service']:

descriptor = self.services[serv_id]['service']['nsd']
functions = self.services[serv_id]['function']
original_nsd_uuid = descriptor['uuid']

##----------------------------------------------------------------##
##----------------------SCRAMBLE PART-----------------------------##
##----------------------------------------------------------------##

# create a set of vnfs for different MANO frameworks through random logic
# Number of splits is by default 2 except if the number of MANOs and number of VNFs are equal.

function_list = self.get_network_functions(descriptor)
rndm_sets = self.random_combination(function_list, mano_list)

if(len(rndm_sets) > 1): # if there are more than 1 MANOs, SCRAMBLE-splitter is called to split the NSD
vnfid_set = [sets[0] for sets in rndm_sets]# vnf-ids of sets 1 and 2

# send the random vnf split to SCRAMBLE Splitter and get back sub NSDs for each split.
splitter_url = os.environ['splitter_url'] 
nsd_to_split = { 'descriptor' : descriptor, 'sets': vnfid_set}

response  = requests.post(splitter_url,
data=json.dumps(nsd_to_split))

nsds_splitted = json.loads(response.text) # get back 2 sets of sub-nsds

else:

nsds_splitted = {"message" : [descriptor]}


# logic to check which vnf is to be send to which MANO

function_pish = [] # list to store vnfs for MAIN_PISHAHANG
main_pish_nsd = {} # string to store nsd for MAIN_PISHAHANG

for i,sets in enumerate(rndm_sets):

if sets[2][0]['type'] == 'MAIN_PISHAHANG':

main_pish_nsd = nsds_splitted['message'][i]

for vnf in functions:
if(vnf['vnfd']['name'] in sets[1]):
function_pish.append(vnf)


elif sets[2][0]['type'] == 'PISHAHANG':

self.send_to_pishahang(serv_id, sets, functions, nsds_splitted['message'][i])

elif sets[2][0]['type'] == 'OSM':

self.send_to_osm(serv_id, sets, functions, nsds_splitted['message'][i])             

# remove the vnfs which are sent to other MANO from self.services[serv_id]['function']
NSD = main_pish_nsd
functions = function_pish
NSD['uuid'] = original_nsd_uuid

self.services[serv_id]['service']['nsd'] = NSD
self.services[serv_id]['function'] = functions

if(functions == []):

## put up a dummy nsr when there is no network functions is available for this mano. So as to keep the unique UUID of this instantiation request in ledger instead of forced rollback.

self.inform_gk_instantiation_scramble(serv_id)

else:
content = {'nsd': NSD,
'functions': functions,
'topology': topology,
'serv_id': serv_id} 
else:
{...} ## unchanged
\end{lstlisting}