\chapter{MANO Scalability}
\label{ch:Scalability}

In this chapter we discuss the two directions we explored to investigate MANO orchestrator scalability. First, we discuss the scalability plugin that was added to pishahang. The scalability plugin adds 3 main functionalities to pishahang, 1) spawn new child instances of pishahang by allocating new physical resources, 2) Redirecting requests from parent MANO to the child instances and 3) managing the state of child instances. Second, we discuss the experiments conducted on OSM and Pishahang to understand the resource utilization. We also propose a more generic framework to characterize and analyze MANO under load.

\include{scalabilityplugin}



\section{Experiments}
One other task under the MANO scalability investigation was to observe the resource utilization in OSM and Pishahang. To do this we used our own python-mano wrappers to instantiate multiple requests at a time. The next step was to decide on the number of service requests to instantiate. We could simply instantiate any number (like 1,000 or 5000) of service requests but we had to make sure all those requests get successfully instantiated. For this, the infrastructure was the only crucial factor. We used a 16 core virtual machine for installing VIM(Openstack). Since one virtual CPU equals 16 physical CPUs, we have 16 * 16 = 256 cores. Hence we first assigned 1 CPU to one service request. We instantiated 256 service requests. They were not successfully instantiated. Next, we came up with another parameter called Requests Per Minute(RPM). The first attempt was setting the RPM to be 60 and instantiating 256 service requests. This run was not successful. The next run was 250 service requests at 60 RPM. The requests failed to get instantiated. The third run was 200 instances at 30 RPM, which was also a failure. The idea was to find the right combination of number of service requests and RPM. Finally 180 requests at 30 RPM was found to be suitable for our experiment. 

Next, we had to decide which VNF image to use for our experiment. We used a basic cirros VNF, we instantiated 180 such service requests. We designed their NSDs to have a single VNFD. 


\subsection{Testbed}

This subsection describes the experimental setup that was required for observing resource utilization in scalability analysis.
\subsubsection{Infrastructure}

We used 5 servers, two were installed with OSM and pishahang. The other two were installed with two openstack versions and the remaining was installed with kubernetes. OSM was connected to one openstack. Pishahang was connected to kubernetes and openstack. The servers had the following machine configuration:
\begin{itemize}
	\item \textbf{OSM (server 1) -} Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 8 core CPU and 64 GB memory
	
	\item \textbf{Pishahang (server 2) -} Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 8 core CPU and 64 GB memory
	\textbf{\item Openstack (server 3) -} Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 16 core CPU and 128 GB memory
	
	\item \textbf{Openstack (server 4) -} Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 16 core CPU and 128 GB memory
	
	\item \textbf{Kubernetes (server 5) -}  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz with 16 core CPU and 128 GB memory
	


\end{itemize}

\subsubsection{Experiment script}

We used a python script to instantiate 180 requests of a cirros image continuously at 30 RPM with the help of python-mano-wrappers. Once all the requests were instantiated, we once again used the wrappers to send the termination requests all at once. We conducted the same experiment three times i.e we had three runs of this experiment to see the variance. This experiment was conducted both on OSM and pishahang.The results of the experiment is discussed in the following sections.


\include{osmresults}

\include{pishahangresults}


\subsection{Summary of issues of the experiment}

The limitations of this experiment:

\begin{itemize}
	\item The VM in which we installed the VIM(openstack) was supposed to use a configuration with only a 16 core CPU. 
	\item Unlike for cirros image, there were issues with successfully instantiating 90 and 180 service requests of ubuntu image despite multiple runs because ubuntu image occupied more memory than the cirros image
	 \item Higher the RPM, lower the success rate.
	\item There is no VM v/s VM or container v/s container comparison i.e. this experiment conducted on OSM and pishahang could not be a fair comparison because OSM doenst not support containerized orchestration and pishahang does not have a stable support for openstack. Hence, we have used openstack for OSM and kubernetes for pishahang.
	
\end{itemize}


\include{mano-benchmarking-framework}
